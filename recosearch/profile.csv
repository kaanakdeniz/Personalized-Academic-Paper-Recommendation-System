title,text,keywords
A Smooth Representation of Belief over SO(3) for Deep Rotation Learning with Uncertainty,smooth representation belief deep rotation learning uncertainty valentin peretroukhin matthew giamou david rosen nicholas greene nicholas roy jonathan kelly institute aerospace studies university toronto laboratory decision systems computer science artiﬁcial intelligence laboratory massachusetts institute technology abstract accurate rotation estimation heart robot perception tasks visual odometry object pose estimation deep neural networks new way perform tasks choice rotation representation important part network design work present novel symmetric matrix representation rotation group important properties suitable learned models satisﬁes smoothness property improves convergence generalization regressing large rotation targets encodes symmetric bingham belief space unit quaternions permitting training uncertainty aware models empirically validate beneﬁts formulation training deep neural rotation regressors data modalities first synthetic point cloud data show representation leads superior predictive accuracy existing representations arbitrary rotation targets second image data collected onboard ground aerial vehicles demonstrate representation amenable effective distribution ood rejection technique signiﬁcantly improves robustness rotation estimates unseen environmental effects corrupted input images requiring explicit likelihood loss stochastic sampling auxiliary classiﬁer capability key safety critical applications detecting novel inputs prevent catastrophic failure learned models introduction rotation estimation constitutes core challenges robotic state estimation given broad interest applying deep learning state estimation tasks involving rotations consider suitability rotation representations domain question rotation parameterization estimation control problems long history aerospace engineering robotics learning unit quaternions known euler parameters popular choice numerical efﬁciency lack singularities simple algebraic geometric structure standard unit quaternion parameterization satisfy important continuity prop erty essential learning arbitrary rotation targets recently detailed address deﬁciency authors derived alternative rotation representations satisfy property lead network performance representations point representa tions quantify network uncertainty important capability safety critical applications fig represent rotations symmetric matrix deﬁnes bingham distribution unit quaternions apply representation deep rotation regression present differentiable layer parameterized show extract notion uncertainty spectrum work introduce novel representation based symmetric matrix combines impor tant properties namely admits smooth global section representation space satisfying continuity property identiﬁed authors deﬁnes bingham distribution unit quaternions amenable novel distribution ood detec tion method additional stochastic sampling auxiliary classiﬁers figure visually summarizes approach experiments synthetic real datasets highlight key advantages approach open source python method experiments finally note representa tion implemented only lines modern deep learning libraries pytorch marginal computational overhead typical learning pipelines work estimating rotations long rich history computer vision robotics depth survey rotation bingham rotation learning https github com utiasstars minq qta qsubj toqtq aaac icdvlbbhmxepuut lcunjkxsiqkkjd zjkgarses ilwosyvinjp nmbue roms eek bsa oijgtr myzgevywawkwst gyrxrl fmprzntr umtjqlli vqu zmeljqnrrohknlraqz qczbdvf mtz ibwrbhok eiifzqo tuspwd biyonzkayuupeez oudahxm uuapmztcyo ojhjx wnojbamzwihprjwi fmsbwt qxr xfdn rgzt iimw vhavfrmg sromqcbif cnlng inio dyxbxifxvttpmkba fhzbprab sibcmifrfk pjmdgdfxqvwqkdbta nxpkdtszfuqx vjfwmmisigkfjlobju eky quqfatfr pxwcgrj krajtre nrzuyv rxznpmugrlfe tthtxuvvxe cedov waunjfnlihpfdkpln eks jqct gwcddafgl sgwblmavml psvsepvja diﬀerentiable qcqp layerq aaacxxicbvdbbtnaen fiopbdoeohbzesfxawrdqxibuqveokegkbrshexjzbhzde cokewp tsee itshimi ukrvx vzmfnxbmslolgruvtpnp gtrqf nobntvf yqqohfbaxmrguckmbyrj uvuenjy dbb jsvjn zify wmuga adl rkdbldcu sgximrfukqzjkiqmvqitfparibtttanavchjgxihzxot zafjtvokgxi ley dquwzaucis kizmik gekeozpcihzf lhv zqpt rxjyneq ljbau hjv kczey nzcqkhk lmwwf szwa kcsvj vkfcqn wthafhppsrfznwszeldm kpadjsej wxhfshx oghb agfakcjidt ejx ipwcnaqx klv lybvusefz qnh sctxil oaf isdss szwzmsb tht nzwpv tlga alwhroe representationunit quaternions neural networksymmetric matrix input dataq aaaclxicbvdlssqwfe dbmcbbecwh ejw lbgywzkmnmjhmmbtrjrtiufodb xougbv ivg ets fmhikubj rkzhrufmjyadmdm yxfpew almkonk vcgmsbfddqvkueo sciucbl twb egojdxqitoemrbc cfq xxm rmsejvvql fluielzm whlfzujynieyumten swyjhgwsxkbjm kddezbfqsdrmezggk bpvwrsttd pgxyjh fnrkighh pyg qzcjoekryj lruuhedcw pbxsm ryxsnvmm tllpmdaqu dzvjb umhd jim ldjrgnqkp lvufukdfqbdsr bkkp dtxfqe aoj ocp gqwsmbxcf jickjnsi yan pivdnvw irp xzit gfhwcw averaging problem formulations solution methods deal directly multiple rotation measurements presented section brieﬂy survey techniques estimate rotations raw sensor data focus prior work incorporates machine learning rotation estimation pipeline review recent work differentiable optimization problems convex relaxation based solutions rotation estimation problems inspired work rotation parameterization robotics common parameterize rotation states elements matrix lie group approach facilitates application gauss newton based optimization local uncertainty quantiﬁcation small perturbations deﬁned tangent space erating point group state estimation contexts applications may eschew full orthogonal matrices positive determinant elements favour lower dimensional representations desirable properties example euler angles well suited analyzing small perturbations steady state ﬂight conventional aircraft reaching singularity practically impossible contrast spacecraft control requires large angle maneuvers singularity free unit quaternions popular choice learning based rotation estimation recent robotics literature focused improving classical pose estimation learned models learning help improve outlier classiﬁcation guide random sample consensus ﬁne tune robust losses fusing learned models rotation classical pipelines shown improve accuracy robustness egomotion estimates vision contexts differentiable solvers proposed incorporate learning bundle adjustment monocular stereo point cloud registration fun damental matrix estimation methods rely differentiating singular value decomposition unrolling local iterative solvers ﬁxed number iterations adding interpretable outputs learned pipeline shown improve generalization paradigm differentiable pipelines suggested tackle array robotics tasks effectiveness learning repre sentations explicitly addressed given represen tation mean surjective mapping authors identiﬁed existence continuous right inverse important learning intuitively existence ensures training signal remains continuous regression tasks reducing errors unseen inputs similarly empirical comparison representations learning complex forward kinematics conducted full pose estimation important robotics applications limit analysis representations pose estimation tasks decoupled rotation translation components rotation component constitutes challenge learning rotations uncertainty common ways extract uncertainty neural networks include approximate variational inference monte carlo dropout bootstrap based uncertainty ensemble models multiple network heads prior work proposed mechanism extends methods targets differentiable quaternion averaging local notion uncertainty tangent space mean additionally learned methods equipped novelty detection mechanisms referred distribution ood detection help account epistemic uncertainty autoencoder based approach ood detection visual navigation task ensure safe control policy novel environments similar approach applied single variational autoencoder novelty detection control policy learning see recent summary ood methods commonly applied classiﬁcation tasks finally unit quaternions important broad body work learning directional statistics enable global notions uncertainty densities like bingham distribution especially useful modelling large error rotational distributions demon strate representation parameterizes bingham belief similar recently published approach uses bingham likelihood learn global uncertainty rotations work differs approach important aspects formulation parsimonious requires only single symmetric matrix parameters encode mode uncertainty bingham belief present analytic gradients approach consid ering generalized qcqp based optimization rotations prove representation admits smooth right inverse demonstrate extract useful notions uncertainty parameterization using explicit bingham likelihood training avoiding complex computation bingham distribution normal ization constant iii symmetric matrices rotation representation deﬁned using set real matrices simple non repeated symmetric minimum eigenvalue eigenvalues arranged matrix mapped unique rotation differ entiable quadratically constrained quadratic program qcqp deﬁned figure problem representation advantages context learned models section show matrix arises data matrix parametric qcqp present analytic derivative show representation continuous sense bingham distribution unit quaternions discuss intimate connection rotation averaging rotations solutions qcqps optimizations involve rotations written constrained quadratic loss xtax min subj deﬁnes set parameterizes rotation constraints data matrix encodes error primi tives data association uncertainty example consider wahba problem problem unit quaternions given set asso ciated vector measurements solves ﬁnd ˆvi min ˆui homogenization vector refers quaternion product convert problem following quadratically constrained quadratic program qcqp problem qcqp find solves qtaq min subj qtq data matrix terms given sum ˆvi ˆui left right quaternion product matrices constructing input data contain vector correspondences constitutes primary challenge rotation estimation consider applying tools high capacity data driven learning task predicting given input end generalize problem consider parametric symmetric matrix problem parametric quaternion qcqp qta min subj qtq fig differentiable qcqp layer representing problem layer takes input symmetric matrix deﬁned parameters solution given minimum eigenspace implicit function theorem derive analytic gradient solving problem problem minimized pair lying dimensional subset antipodal unit quaternions minimum eigenspace simple minimal eigenvalue problem admits solution quotient space unit quaternions represents obtained identifying antipodal points single rotation solution eigendecomposition real symmetric matrix implemented efﬁciently deep learning frameworks symeig function pytorch practice encode restrictions ensure ﬁnd impede training note complement set measure zero differentiating problem wrt derivative respect guaranteed exist simple implicit function theorem show vec denotes moore penrose pseudo inverse kronecker product refers identity matrix gradient implemented symeig function pytorch efﬁciently implemented framework allows batch linear system solves smooth global section consider surjective map rotation matrix corresponding argmin qtaq terized deﬁnes quadratic cost function parame surjectivity follows admits global section theorem minq qta qsubj toqtq aaac icdvlbbhmxepuut lcunjkxsiqkkjd zjkgarses ilwosyvinjp nmbue roms eek bsa oijgtr myzgevywawkwst gyrxrl fmprzntr umtjqlli vqu zmeljqnrrohknlraqz qczbdvf mtz ibwrbhok eiifzqo tuspwd biyonzkayuupeez oudahxm uuapmztcyo ojhjx wnojbamzwihprjwi fmsbwt qxr xfdn rgzt iimw vhavfrmg sromqcbif cnlng inio dyxbxifxvttpmkba fhzbprab sibcmifrfk pjmdgdfxqvwqkdbta nxpkdtszfuqx vjfwmmisigkfjlobju eky quqfatfr pxwcgrj krajtre nrzuyv rxznpmugrlfe tthtxuvvxe cedov waunjfnlihpfdkpln eks jqct gwcddafgl sgwblmavml psvsepvja min eigenvalueimplicit function theorem noted section authors identiﬁed existence continuous right inverse section important learning authors topological arguments demonstrate continuous representation only possible dimension embedding space greater case dimensional unit quater nions discontinuity manifests rotations dimensional representation present proof non unique continuous mapping exists smooth consider theorem smooth global section surjective map returns rotation matrix deﬁned antipodal unit quaternions minimize problem exists smooth global mapping section proof recall mapping unit quaternions rotations continuous surjective identiﬁes antipodal unit quaternions sends rotation shows diffeomorphic smooth manifolds sufﬁces show global section exists arbitrary element deﬁne qqt representatives note well deﬁned arbitrary elements selecting representative leads output construction orthogonal projection operator dimensional orthog onal complement span span follows deﬁnes symmetric matrix simple minimum eigenvalue eigenspace associated minimum eigenvalue precisely span span turn implies qqt bingham exp λdc xtdλdtx exp normalization constant orthogonal matrix formed orthogonal unit column vectors fourth mutually orthogonal unit vector matrix dispersion coefﬁcients given diag λdc note dispersion coefﬁcients eigenvalues matrix dλdt λdc controls spread probability mass direction given small magnitude λdc implying large spread vice versa mode distribution given λdc λdc λdc λdc λdc crucially bingham bingham careful diagonalization represen tation fully bingham namely ensure mode density given solution problem set dλdt smallest eigenvalue largest eigenvalue recover dispersion coefﬁcients λdc evaluate non zero eigenvalues deﬁning equivalent density bingham eigen values ascending order equation λdc λdc establishes relation eigenvalue gaps dispersion bingham density deﬁned λdc using deep learning consider applying formulation learning task ﬁtting set parameters deep rotation regressor minimizes training loss generalizing unseen data depicted figure qtg self supervised learning argmin global section surjective map see inspection global section smooth continuous locally differentiable represent using diffeomorphic preimages smooth function qqt bingham distribution show representation space deﬁnes bingham distribution unit quaternions may regard encoding belief rotations facilitates training rotation models uncertainty bingham distribution antipodally sym metric distribution derived zero mean gaussian conditioned lie unit hypersphere unit quaternions probability density function self supervised learning applications requires rotation matrix transform set data representation admits differentiable transformation rotation matrix unit quaternion rotation matrix projection layer solves pair antipodal unit quaternions admits smooth global section avoid discontinuity identiﬁed back propagation work limit attention supervised rotation regression problem directly compare continuous representation supervised learning rotation loss functions supervised learning rotations number possible choices loss functions deﬁned survey invariant metrics suitable task presented example possible loss functions include quat qgt qgt dquat chord rgt dchord rgt ang rgt dang rgt qgt gtdλdtqgt bingham qgt min dquat qgt dchord rgt qgt rrt rgt log dang rgt deﬁned formulation log fully bingham density possible likelihood loss bingham train bingham belief similar manner who alternate parameter representation normalization constant hypergeometric function non trivial compute authors evaluate constant using ﬁxed basis non linear approximation aided precomputed look table work opt compare point representations leave comparison belief representations future work experiments chordal loss chord applied rotation matrix unit quaternion outputs eschewing likelihood loss still extract useful notion uncertainty deep neural network regression using eigenvalues matrix see present ﬁnal interpretation representation speciﬁcally catered structure deep models rotation averaging take inspiration neural network based pose regression interpolation set base poses elucidate connection speciﬁcally rotation regression relating rotation averaging learned set base rotations using chordal distance base rotations span training data argue represent notion epistemic uncertainty distance training samples explicit likelihood loss consider given rotation samples expressed unit quaternions rotation average according chordal metric computed qdchord argmin dchord qiqt deﬁned equation weighted averaging note possible metrics converting representations chord qgt quat quat chordal distance shown effective initialization optimization slam negative qiqt associated λmin average requires λmax computes eigenvector version operation discussed next consider feed forward neural network uses representation network regressing parameters ﬁnal fully connected layer prior output separate components last layer parameterized weight matrix transforms input rest network image coefﬁcients given output network given bias vector wiγi refers ith column second line follows linearity mapping deﬁned equation manner view rotation regression representation analogous computing weighted chordal average set learned base orientations rameterized symmetric matrices deﬁned column vectors training network tunes bases weight function dispersion thresholding epistemic uncertainty qiqt positive semi deﬁnite psd matrix called inertia matrix context bingham maximum qiqt likelihood estimation operation compute maximum likelihood estimate mode bingham belief given samples symmetric representation necessarily psd perform canonicalization section iii interpret negative inertia matrix making connection bingham beliefs λdc measure network uncertainty ﬁnd empirically works surprisingly well measure epistemic uncertainty model uncertainty explicit penalty training remove ood samples compute threshold based quantiles training data retaining lowest qth quantile call technique dispersion thresholding intimate connection rotation averaging bingham densities work required elucidate exactly notion uncertainty present uncertainty aware loss like bingham leave investigation future work note metric similar argument unit quaternion representation normalization operation corresponds mean qdquat argminq dquat note interpretation matrix refer directly bingham dispersion matrix parameterized inertia matrix inverting implicit equation see ﬁnd empirically norm wiγi work well uncertainty metric rotation representations conjecture basis rotations sufﬁcient spread space cover training distribution test time ood inputs xood result weights xood likely average bases due compact nature conversely samples closer training data likely nearer learned bases result larger experiments present results extensive synthetic real experiments validate beneﬁts representation case compare representations unit quaternions normalized vector outlined figure best performing continuous dimensional representation symmetric matrix representation report rotational errors degrees based dang wahba problem synthetic data first simulated dataset desired rotation sets unit vectors known correspondence considered generative model ˆrui sampled unit sphere training test example sampled exp deﬁne capitalized exponential map φmax set compared training test errors learning rates selected range using adam optimizer taking inspiration employed dynamic training set constructed mini batch sampled rotations noisy matches deﬁned epoch ﬁve mini batches neural network structure mimicked convolutional structure presented train models chord fig angular errors trials learning rates sampled range log uniform φmax show percentiles epoch note regressing rotation matrices directly satisfy continuity property chose include representation fared experiments fig box whiskers plots settings φmax rotation representations applied synthetic data unit quaternion representation results large errors φmax sample shapenet airplane category randomly rotate point clouds generate training test data mean angular errors shapenet dataset trials learning rates sampled range log uniform plot percentiles epoch fig summary shapenet experiments figure displays results experimental trials learning rates synthetic data arbitrary rotation targets continuous representations outperform discontinuous unit quaternions corroborating results symmetric representation achieves lowest errors across training testing figure depicts performance representation training data restricted maximum angles hypothesized dis continuity unit quaternion manifests regression targets angles magnitude near degrees wahba problem shapenet next recreated experiment airplane point clouds shapenet held point clouds iteration training randomly selected single point cloud transformed sampled rotation matrices figure test time applied random rotations held point clouds figure compares performance representation unit quaternions representation results similar synthetic case figure epoch train meanerror deg dquata epoch test quat log error quat quat epoch train meanerror deg dquata epoch test table relative rotation learning kitti dataset representations training uncorrupted data show ood technique dramatically improve rotation accuracy rejecting inputs likely lead high error sequence model mean error kept mean error kept precision normal test corrupted test quat auto encoder section pairs pairs pairs quat quat thresholding based thresholding based corrupted images rejected sequence sequence corrupted uncorrupted images corrupted images fig mean rotation errors test sequences kitti odometry dataset relative rotation targets small see signiﬁcant difference baseline accuracy dispersion thresholding technique section signiﬁcantly improve performance outperforms alternative ood method based reconstruction error using auto encoder see table full statistics test sets fig dispersion thresholding metric plotted data corresponding test sequence refer text train test split corruption applied test data altering training data thresholding leads effective ood rejection scheme need retrain model visual rotation only egomotion estimation kitti third representation learn relative rotation images kitti odometry dataset sequential correcting independently estimating rotation learned models potential improve classical visual odometry pipelines note limit translation camera rotation estimated independently translation pair images end built convolutional neural network predicted relative camera orientation sequential images recorded sequences residential city categories dataset selected sequences testing trained models remaining sequences accord results figure found little change performance across representations rota tion magnitudes regression targets kitti typically order degree found metric acted useful measure epistemic uncertainty error deg threshq testtrain training city seq seq road seq corrupted randominputtr testsequence meanerror deg testsequence global shutter camera mounted micro aerial vehicle depicted figure considered dataset vehicle undergoes dramatic lighting scene changes transitions outdoor indoor environment trained model using outdoor images ground truth rotation targets supplied onboard visual inertial odometry system note primarily interested characterizing dispersion thresholding technique coarse rotation targets sufﬁced identical network architecture kitti experiments figure details performance representation representation paired auto encoder ood rejection method observe compared kitti experiment based ood rejection technique fares data believe result way partitioned mav dataset images split train test split using random selection test samples recorded near temporally spatially training samples method performs par test sets require training separate classiﬁer vii discussion limitations negligible rotation representation important design criterion state estimation single representation optimal contexts exception importantly differentiable layer solves problem incurs computational cost test time slow learning cost training compared representations require only basic operations like normalization practice ﬁnd common convolutional networks training bottlenecked parts learning pipeline representation adds marginal processing time com pact models training time increased representation include symmetric matrices minimal eigenvalue non simple work enforce explicitly assume happen machine precision practice ﬁnd occurs exceedingly rarely explicitly enforcing constraint direction future research viii conclusions future work work presented novel representation based symmetric matrix representation space interpreted data matrix qcqp deﬁning bingham belief unit quaternions parameterizing weighted rotation average set base rotations proved representation admits smooth global section developed ood rejection method based solely eigenvalues avenues future work include combining representation bingham likeli hood loss investigating connection epistemic uncertainty rotation averaging finally especially interested leveraging representation improve reliability robustness ultimately safety learned perception algorithms real world settings mav point grey flea global shutter camera environments outdoor indoor transition iii mean rotation errors test sequences mav dataset using model trained outdoor data auto encoder rejection performs well technique able match performance requiring separate model fig summary mav experiments validate notion manually corrupted kitti test images setting random rectangular regions pixels uniform black figure displays growth magnitude manifest metric data similar seen training figure displays estimation error test sequence corruption stress corruptions only applied test data highlight numerically table able reject corrupted images images likely lead high test error test sequences observed nearly constant mean rotation error formulation data corruption auto encoder ood method compared thresholding approach auto encoder based ood technique inspired work novelty detection mobile robotics training set trained auto encoder using pixel based reconstruction loss rejected test time inputs mean pixel reconstruction error qth percentile training figure table detail results demonstrate representation paired performs signiﬁcantly represen tation based rejection method importantly stress notion uncertainty embedded representation require training auxiliary ood classiﬁer mav indoor outdoor dataset finally applied representation task training relative rotation model data collected using flea point grey flea cameraiiiiiiivoutdooroutdoor indooroutdoor indoor transition meanerror deg references alexander amini wilko schwarting guy rosman brandon araki sertac karaman daniela rus variational autoencoder end end control autonomous driving novelty detection ieee rsj intl conf intelligent robots training biasing systems iros pages landis markley yang cheng john crassidis yaakov oshman averaging quaternions journal guidance control dynamics alexander meinke matthias hein neural networks provably know don know intl conf learning repre sentations iclr timothy barfoot state estimation robotics cambridge university press christopher bingham antipodally symmetric distribution sphere annals statistics eric brachmann carsten rother neural guided ransac learn ing sample model hypotheses intl conf computer vision iccv carlone tron daniilidis dellaert initialization techniques slam survey rotation estimation pose graph ieee intl conf robotics automation icra optimization pages angel chang thomas funkhouser leonidas guibas pat han rahan qixing huang zimo silvio savarese manolis savva shuran song hao jianxiong xiao fisher shapenet rich model repository technical report arxiv ronald clark michael bloesch jan czarnowski stefan leutenegger andrew davison learning solve nonlinear least squares monocular stereo european conf computer vision eccv darling demars uncertainty propagation correlated quaternion euclidean states using partially conditioned gaussian intl conf fusion fusion pages mixtures ian osband charles blundell alexander pritzel benjamin van roy advances neural deep exploration bootstrapped dqn processing systems neurips pages valentin peretroukhin jonathan kelly dpc net deep pose cor rection visual localization ieee robotics automation letters valentin peretroukhin brandon wagstaff jonathan kelly deep probabilistic regression elements using quaternion aver aging uncertainty injection cvpr workshop uncertainty robustness deep visual learning pages ren ranftl vladlen koltun deep fundamental matrix estimation european conf computer vision eccv volume pages charles richter nicholas roy safe visual navigation deep robotics science systems learning novelty detection rss david rosen luca carlone afonso bandeira john leonard sync certiﬁably correct algorithm synchronization intl robotics research special euclidean group torsten sattler qunjie zhou marc pollefeys laura leal taixe understanding limitations cnn based absolute camera pose ieee conf computer vision pattern recognition regression cvpr pages james diebel representing attitude euler angles unit quaternions rotation vectors technical report stanford university davide scaramuzza friedrich fraundorfer visual odometry tuto rial ieee robotics automation magazine bernard etkin dynamics atmospheric ﬂight wiley yarin gal uncertainty deep learning phd thesis university cambridge geiger lenz stiller urtasun vision meets robotics kitti dataset intl robotics research igor glitschenski wilko schwarting roshni sahoo alexander amini sertac karaman daniela rus deep orientation uncertainty learn ing based bingham loss intl conf learning representations iclr jared glover leslie pack kaelbling tracking rotations quaternion bingham filter technical report mit csail mit reinhard grassmann jessica burgner kahrs merits joint space orientation representations learning forward kinematics robotics science systems rss richard hartley jochen trumpf yuchao dai hongdong rota tion averaging intl computer vision berthold horn closed form solution absolute orientation using unit quaternions optical society america peter karkus xiao david hsu leslie kaelbling wee sun lee tomas lozano perez differentiable algorithm networks composable robot learning robotics science systems rss laurent kneip roland siegwart marc pollefeys finding exact rotation images independently translation european conf computer vision eccv pages balaji lakshminarayanan alexander pritzel charles blundell sim ple scalable predictive uncertainty estimation using deep ensembles advances neural processing systems neurips pages jan magnus differentiating eigenvalues eigenvectors econometric theory joan sol jeremie deray dinesh atchuthan micro lie theory state estimation robotics arxiv suvrit sra directional statistics machine learning brief review arxiv stat chengzhou tang ping tan net dense bundle adjustment networks intl conf learning representations iclr grace wahba problem least squares estimate satellite attitude siam review yue wang justin solomon deep closest point learning intl conf computer representations point cloud registration vision iccv bong wie peter barba quaternion feedback spacecraft large angle maneuvers journal guidance control dynamics heng yang luca carlone quaternion based certiﬁably optimal solution wahba problem outliers intl conf computer vision iccv pages kwang moo eduard trulls yuki ono vincent lepetit mathieu salzmann pascal fua learning find correspondences ieee conf computer vision pattern recognition cvpr pages brady zhou philipp ahenb uhl vladlen koltun computer vision matter action science robotics zhou connelly barnes jingwan jimei yang hao ieee continuity rotation representations neural networks conf computer vision pattern recognition cvpr pages,"['rotation', 'representation', 'learning', 'matrix', 'bingham']"
DeepMark++ CenterNet-based Clothing Detection,deepmark centernet based clothing detection alexey sidnev alexander krapivin alexey trushkov ekaterina krasikova maxim kazakov huawei research center nizhny novgorod russia lobachevsky state university nizhny novgorod russia national research university higher school economics nizhny novgorod russia sidnev alexey krapivin alexander trushkov alexey krasikova ekaterina kazakov maxim huawei com abstract single stage approach fast clothing detection modiﬁcation multi target network centernet proposed paper introduce powerful post processing techniques may applied increase quality keypoint localization tasks semantic keypoint grouping approach post processing techniques possible achieve state art accuracy map bounding box detection task map landmark detection task deepfashion vali dation dataset achieved second place deepfashion challenge map test dataset proposed approach low power devices high accuracy requiring post processing techniques introduction recent studies keypoints referred landmarks proved distinc tive robust representations visual analysis class keypoint based methods computer vision includes detection processing keypoints meth ods utilized tasks object detection pose estimation facial landmark recognition performance models operate keypoints highly depends number unique landmarks ﬁned task may considerably large modern datasets deepfashion newest fash ion datasets annotations classes characterized set keypoints unique ones total paper propose study clothing land mark detection task deepfashion dataset well approach deal efﬁciently figure speed accuracy trade object detection land mark estimation deepfashion validation dataset nms post processing applied model work general numerous applications key points estimation task instance keypoints directly identify human pose locate facial land marks part object detection pipeline keypoint based object detection methods gaining popularity recent papers especially simpler faster accurate correspond ing bounding box based detectors previous approaches required anchor boxes manually designed train detectors series anchor free object detectors developed aim predicting bounding box keypoints trying object anchor relying man ually designed anchors match objects cornernet performance coco datasets improved signiﬁcantly subsequently variants keypoint detection based stage detectors came existence centernet inference time mapdla dla dla dla dla dla landmarksboxes figure scheme proposed approach paper focuses clothing landmark prediction clothing detection tasks using deepfashion datasets baseline approach landmark estimation built mask cnn due stage nature substantially heavy difﬁcult low power devices aim propose lightweight architec ture heavy requirements perfectly met centernet operates directly keypoints proposed approach approach based centernet architecture see figure solves tasks simultaneously object detection keypoint location estimation deepfashion dataset contains classes channels predict probabilities object centers classes center heatmap figure object center deﬁned center bounding box additional channels output feature map reﬁne center coordinates width height predicted directly fashion landmark estimation task involves estimat ing keypoint locations item clothing image coarse locations keypoints regressed relative displacements box center coarse key points figure reﬁne keypoint location heatmap probabilities keypoint type local maximum high conﬁdence heatmap reﬁned keypoint position similar detection case additional channels obtain cise landmark coordinates model inference coarse keypoint location replaced closest reﬁned keypoint position semantic keypoint grouping ﬁrst steps involved solving keypoint tection tasks deﬁning model output number figure gpu memory consumption training iteration time rtx input resolution batch size dla resnet hourglass time measured optimization step batch loading gpu forward pass backward pass gpu memory measured using nvidia smi tool keypoints category varies skirt long sleeve outerwear deepfashion dataset total number unique keypoints simple approach concatenate keypoints category deal keypoint separately directly predicting keypoints leads huge number output channels coarse keypoints keypoint heatmap evident clothing landmarks sub set example shorts require unique keypoints represented subset trousers keypoints semantic grouping rule deﬁned follows identical semantic meaning keypoints collar cen ter top sleeve edge categories merged group approach enables forma tion groups reduces number output channels semantic grouping approach reduces training memory consumption times respec tively accuracy drops see figure reduction enables larger batches model training post processing techniques developed post processing techniques crease model accuracy compromising perfor mance center rescoring ﬁrst technique recalculation detection con ﬁdence score using keypoint scores keypoint heatmap scorebbox original detection conﬁ backbone object detec onkeypointdetec oncenter heatmapscore objectsize centeroffset coarse keypoints keypoint heatmapscore keypoint offset focal lossl lossl lossfocal lossl lossl lossbboxdownscalekeypoints optimization step time memory usage dla resnet hourglass keypoints keypoint groups dence score center heatmap scorekps average score reﬁned keypoints predicted cate gory keypoint heatmap ﬁnal detection conﬁ dence scores calculated following formula score scorebbox scorekps heatmap rescoring gaussian kernel second technique general approach applied keypoint based architecture heatmap center keypoint scores taking training procedure account expect connected neighbors item object improve estimation heatmap value applied following formula convolution operation gaussian kernel standard deviation experimen tal results show model proposed technique improves localization peaks values cor respond object centers keypoints scores similar operation considered part proposed method keypoint location reﬁnement third technique recalculation reﬁned keypoint locations using coarse positions ref ined ﬁned keypoint location heatmap coarse coarse positions predicted offsets object centers ﬁnal keypoint locations calculated fol lowing expression ref ined coarse keypoint heatmap rescoring fourth technique keypoint heatmap rescoring mask coarse keypoint location mask heatmap zero values default set mask coarse keypoint position ﬁll neighbor values gaussian function standard deviation sigma min width height width height object size keypoint heatmap rescored following expression ˆhkps hkps mask post processing map map box base nms technique technique technique technique infer time table post processing techniques applied indepen dently hourglass technique numbers correspond numbers section multi inference strategies consider extra inference strategies fusing model outputs original ﬂipped images equal weights fusing model results original image down scaled upscaled multipliers proposed techniques increase accuracy require model ferences signiﬁcantly affecting entire processing time keypoint reﬁnement network ﬁnal stage detection results reﬁned posefix model agnostic pose reﬁnement method method learns typical error distributions pose estimation method corrects mistakes testing stage trained set posefix models using num ber classes deepfashion dataset inference results method training set train models subsequently applied trained posefix models result results experiments performed publicly avail able deepfashion challenge dataset contains images training set images validation set centernet coco model object tection initial checkpoint performed experiments hourglass backbone adam optimizer achieve state art results table object detection keypoint estimation tasks deepfashion validation dataset hourglass model trained epochs batch size images learning rate schedule epochs epochs techniques increase map reduce map box simul taneously note bounding box detection keypoint estimation sults object may iou oks ground truth example bounding box detected correctly key points case technique involves lowering score false positive keypoints advisable corresponding true posi tive bounding box suffers lowered score conclusion new approach proposed adaptation cen ternet clothing landmark estimation tasks state art accuracy achieved deepfashion dataset applying post processing techniques clothing detection hit map clothing landmark estimation map proposed approach post processing techniques takes image rtx dla yields considerably high accuracy map map box clothing detection tasks see figure references ming chen yingjie qin lizhe yunquan sun proving fashion landmark detection dual attention fea ieee international conference ture enhancement computer vision iccv workshops oct yuying ruimao zhang xiaogang wang xiaoou tang ping luo deepfashion versatile benchmark tection pose estimation segmentation identiﬁcation clothing images proceedings ieee conference computer vision pattern recognition pages kaiming georgia gkioxari piotr doll ross girshick mask cnn corr abs hei law jia deng cornernet detecting objects paired keypoints proceedings european confer ence computer vision eccv pages wei liu dragomir anguelov dumitru erhan christian szegedy scott reed cheng yang alexander berg ssd single shot multibox detector european con ference computer vision pages springer gyeongsik moon yong chang kyoung lee poseﬁx model agnostic general human pose reﬁnement net work alejandro newell kaiyu yang jia deng stacked hour glass networks human pose estimation alexey sidnev alexey trushkov maxim kazakov ivan rolev vladislav sorokin deepmark shot clothing detection ieee international conference com puter vision iccv workshops oct feng zhang xiatian zhu hanbin dai mao zhu distribution aware coordinate representation human pose estimation arxiv preprint arxiv zhanpeng zhang ping luo chen change loy xiaoou tang facial landmark detection deep multi task learning european conference computer vision pages springer xingyi zhou dequan wang philipp ahenb uhl jects points arxiv preprint arxiv approach mask cnn deepmark dafe hourglass hourglass map map box table accuracy comparison proposed alternative proaches deepfashion validation dataset metric resolution base post processing nms flip multiscale posefix map map box table clothing detection landmark estimation hourglass resolution experi ments next technique added previous ones post processing refers applying techniques sec tion approach technique technique technique technique mutiscale parameter value center heatmap keypoint heatmap center heatmap keypoint heatmap multipliers table parameters post processing multi inference tech niques epochs hourglass model ﬁne tuned hourglass epochs batch size images epochs epochs considered fast post processing techniques bound ing box non maximum suppression techniques section individual table combined ble effectiveness technique shown dur ing experiments target increase keypoint estimation accuracy object detection accu racy due reason object detection increased only map box techniques added map map parameters post processing techniques determined grid searching step small validation subset images,"['keypoint', 'detection', 'keypoints', 'map', 'object']"
Face Authentication from Grayscale Coded Light Field,face authentication grayscale coded light field dana weitzner david mendlovic raja giryes school electrical engineering faculty engineering tel aviv university abstract face veriﬁcation fast growing authentication tool eryday systems smartphones current face recognition methods accurate suggested recently may wish add sensor lutions reliable robust spooﬁng using print person face requires additional expensive depth sensor mitigate propose novel authentication system based slim grayscale coded light ﬁeld imaging reconstruc tion free fast anti spooﬁng mechanism working directly coded image followed multi view multi modal face veriﬁcation network given grayscale data low depth map achieves competitive results rgb case demonstrate effectiveness solution simulated rgbd version lfw made public set real faces acquired light ﬁeld computational camera index terms anti spooﬁng biometrics coded light ﬁeld depth sensing facial recognition introduction automated biometric authentication systems creasingly popular recent years mean identity ver iﬁcation options facial recognition widely thanks abundant labeled facial images online advances deep learning techniques work focus task face based user authentication face recognition methods based rgb data achieve high accuracy color images sufﬁcient face veriﬁcation insufﬁcient complete authentication system robust spooﬁng may present print face system ensure authenticity user existing solutions add depth sensor based time flight structured light technologies compared standard setup addition technologies increases cost authentication system great interest especially low cost devices system increase price resilient spooﬁng light ﬁeld sensors capture color depth formation may face authentication fig anti spooﬁng demonstrated images obtained light ﬁeld prototype rejecting curved printed age center left ﬂat printed image center right ﬂat image presented smartphone right anti spooﬁng algorithm operates coded light ﬁeld image require depth images shown here only demonstration purpose details see section systems images captured methods coded masks coded apertures microlenses pinhole arrays solutions impractical pensive bulky require large amount storage post processing time irrelevant bedded systems smartphones recently marwah introduced concept compressed photography reconstruct high resolution coded projection measured single sensor allows compact system depth color contribution work rely concept compressed introduce novel low cost face authentica tion system major advantages allows forming anti spooﬁng operation efﬁciently uses only grayscale camera binary coding mask makes system inexpensive reducing achievable accuracy signiﬁcantly coded light field face authentication now turn novel grayscale coded based authentication system first present cod ing scheme enables fast reconstruction show anti spooﬁng mechanism handle face veriﬁcation grayscale images coded capturing suggest following simple model grayscale quisition simplicity assume coding only views view view effective coding matrices drawn spatial projections coding mask pixel spatial location coded image modeled viewi full reconstruction views obtained using sparse coding deep learning methods task face authentication show reconstruction needed coding mask may random distribution measured system calibration known using knowledge obtain fast sparse construction views exploiting mask distribution random binary mask sensor pixels only view pixels locations easily computed smi smi denotes sparse mask pixels only viewi captured sensor dicator function may obtain free recon structed sparse view viewi smi setup trades resolution light efﬁciency number views coded factors opti mized speciﬁc application angles coded create accurate depth map coding mask pattern optimized given speciﬁc system geometry determines shift coding matri ces focus case only views possible extend using technique only constraint resolution pixels correspond just gle controlled changing resolution captured image light efﬁciency case angles assume light efﬁciency implies later coded image quarter pixels belong solely just angles exploit face recognition low resolution ages loss encoding process fail veriﬁcation task technique limited grayscale images applied color images mask bayer pattern adjustments complicate imple mentation increase manufacturing cost cap turing color sacriﬁces resolution light efﬁ ciency focus grayscale case showing depth compensate absence color face veriﬁcation task note light efﬁciency means quar ter pixels view trivially reconstructed assuming sensor resolution reconstructed sparse views yield pixels randomly spaced original resolution notice state art rgb face recognition networks receive faces resolution may free reconstructions sufﬁcient task authentication experiments show case anti spooﬁng reliable face authentication system ensure tual face captured printed image face order veriﬁcation systems pensive scanners time flight structured light detect depth cost notice reconstruction process time consuming systems power inefﬁcient sensitive bient daylight only produce depth signal images hold promise task face authentica tion capture depth intensity following simple idea detecting coded image object need fully reconstruct object method relies disparity map plane captured stereo setting plane plane space deﬁned equation suggest standard stereo setting transformation clidean image spaces given baseline disparity measured pixel principle point image pixel focal length combining equations notice implies case disparity afﬁne respect image coordinates case ﬂat object estimate entire disparity map sampled points leads following simple anti spooﬁng tech nique assume captured face ﬂat applying free reconstruction previous section basic interpolation conducted followed local dis parity calculation speciﬁed image points left sparse view projected new estimation right sparse view applying afﬁne disparity map correspond ing calculated disparity values dplane view viewl dplane similarity measure applied projected right view view captured sparse right view viewr naturally expect similarity lower captured objects non ﬂat disparity maps found comparing average distance cubic interpolated sparse images results face veriﬁcation works approach veriﬁcation task using metric learning way given ﬁne accurate met ric determine faces belong person show combining multi view multi modal depth intensity approach power large scale trained neural network enables competitive results face veriﬁcation task grayscale coded data inspired mvcnn deals objects shape retrieval faces applied multi view proach cnn branches learning jections face original work handle multi modal data weights shared differ ent input features concatenated pooled network structure may summarized follows input left view right view depth map fed independent inception resnet backbone choose network public trained model trained million faces gface concatenate output features feed fully connected layers triplet loss ﬁnal features learn embedding data generation major challenge face veriﬁcation coded amount needed data dataset contains tensity depth type acquire camera suitable face recognition requires identities note leading networks face recognition trained millions identities hundred million images evaluate framework generate types data simulated coded data dataset coded data prototype created calibration data prototype utilized synthetic dataset creation following manner grayscale lfw generate data strategy creates face model rgb age published create face reconstructions labeled faces wild dataset lfw model includes point cloud triangulated mesh detailed texture using relationship depth disparity measured using prototype convert point cloud disparity map warp model views allows trans ferring networks trained lfw data generated system gives disparity maps compared calculated direct point cloud projections grayscale glf faces addition captured faces people using system prototype produce glf faces dataset testing anti spooﬁng mech anism asses generalization veriﬁcation net work real data prototype captured sequential separate views coding mask grayscale sensor just captured views simulate coding works using prototype show simulated coding resembles physical coding well believe experiment real data simulated coding valid proof concept experiments anti spooﬁng test anti spooﬁng concept conduct following experiment synthetic data using lfw database created resembles depth resolution achieved system project grayscale left view ﬂat right view randomized disparity plane param eters simulate acquisition process resulting sparse views real ﬂat projections given sparse left view sampled disparity create projected sparse right view section measure similarity captured simulated projected sparse right views loss bicu bic interpolations similarity distributions plotted fig showing clear separation ﬂat deep faces repeated process glf faces dataset cap tured system partial prototype contains views ﬂat curved surfaces partial cylinders pairs views real faces randomly sampled views preserve scale histograms shown fig exhibit clear cut separa tion synthetic case case method still save heavy computation time obvious spooﬁng cases may common type notably error curved surfaces still distinctively smaller actual faces non planar roc curves anti spooﬁng error based classiﬁer shown fig veriﬁcation depth images prevents complicated spooﬁng scenarios applied only small fraction scans detected ﬁrst cheap anti spooﬁng test ﬁrst work coded data com pare method landmarks depth ldf method state art full database presented only relevant method comparison terms data processed computation synthetic data real data roc curve fig anti spooﬁng results average error histograms synthetic projections error ﬂat case generally smaller views printed image face average error glf faces database including ﬂat curved images roc curve synthetic blue real orange cases data ldf synthetic real table average acer eer facenet facenet accuracy comments rgb images folds ﬁnetuned images fold images folds table average veriﬁcation accuracy lfw sources report results using terms mea sures coded dataset repeated experiment training binary classiﬁcation genuine spooﬁng mixing attack types warped planar paper case keeping amount examples class equal split data test set report average classiﬁcation error rate acer equal error rate eer experiments random data split evaluating strategies glf faces outperform result acer compared achieved ldf synthetic lfw acer compared achieved ldf results summarized table face veriﬁcation report results following unrestricted labeled data protocol lfw fold cross validation report competitive average accuracy lfw data comparison original trained network achieves accuracy lfw grayscale lfw fine tuning trained model single branch inception resnet channel image containing grayscale views depth channel accuracy shows beneﬁts architecture grayscale faces network trained thetic lfw data achieves accuracy randomly sam pled pairs matching mismatching identities end end ﬁne tuning system data increases accuracy test open set manner people training set ﬁne tuning differ ent people test set test set network transferred fine tuned accuracy table average veriﬁcation accuracy glf dataset cases ﬁne tuning tables summarize veriﬁcation experiments results conclusion conclude work presents novel face authentica tion system based grayscale coded eliminating need complicated possibly expensive reconstruction ﬂow proof concept includes fast simple anti spooﬁng mechanism works directly coded image achieved competitive results face veriﬁcation task based coded data showing successful manifesta tion concept application optimized sensing systems printing image easy fraud able detect effective way useful real life products note focus work reliable low cost system face authentication overcome possible adversaries anti spooﬁng methods tricked given effort clearly create model person scan fool system based technologies well video combined solution overcome challenging spooﬁng attempts leave future work cao shen xie parkhi zisser man vggface dataset recognising faces across pose age international conference auto matic face gesture recognition pengfei dou shishir shah ioannis kakadi aris end end face reconstruction deep neu ral networks ieee conference computer sion pattern recognition cvpr tal hassner viewing real world faces ieee international conference computer vision iccv december matan sela elad richardson ron kimmel unre stricted facial geometry reconstruction using image image translation arxiv matan sela elad richardson ron kimmel restricted facial geometry reconstruction using image image translation ieee international confer ence computer vision iccv gary huang manu ramesh tamara berg erik learned miller labeled faces wild database studying face recognition unconstrained environ ments oﬁr nabati david mendlovic raja giryes fast accurate reconstruction compressed color light ﬁeld corr vol abs chiesa dugelay advanced face presentation attack detection light ﬁeld database inter national conference biometrics special interest group biosig sep sepas moghaddam pereira correia light ﬁeld based face presentation attack detection reviewing benchmarking step ieee transactions forensics security vol july gary huang erik learned miller labeled faces wild updates new reporting proce dures references florian schroff dmitry kalenichenko james philbin facenet uniﬁed embedding face recog nition clustering corr vol abs hao wang yitong wang zheng zhou xing zhifeng dihong gong jingchao zhou wei liu cos face large margin cosine loss deep face recogni tion corr vol abs yandong wen kaipeng zhang zhifeng qiao discriminative feature learning approach deep face recognition eccv ward meers face recognition using time ﬂight camera sixth international confer ence computer graphics imaging visualiza tion cgiv vol iphone device https developer apple com library archive documentation deviceinformation reference iosdevicecompatibility cameras cameras html apple_ref doc uid kshitij marwah gordon wetzstein yosuke bando ramesh raskar compressive light ﬁeld photography using overcomplete dictionaries optimized projec tions acm transactions graphics tog vol martin weis jack lin dai taguchi takaaki manaka analysis transient cur mitsumasa iwamoto rents organic ﬁeld effect transistor time ﬂight method journal physical chemistry vol tyler bell beiwen song zhang structured light techniques applications ameri cancer society hang subhransu maji evangelos kalogerakis erik learned miller multi view convolutional neural networks shape recognition christian szegedy sergey ioffe vincent van houcke inception inception resnet pact residual connections learning corr vol abs david sandberg face recognition using tensorﬂow https github com davidsandberg facenet,"['face', 'data', 'coded', 'spooﬁng', 'image']"
GoodPoint Unsupervised Learning of Keypoint Detection and Description,goodpoint unsupervised learning keypoint detection description anatoly belikov alexey potapov singularitynet june abstract paper introduces new algorithm unsupervised learning keypoint detectors descriptors demonstrates fast convergence performance across diﬀerent datasets training procedure uses homographic transformation images proposed model learns detect points generate descriptors pairs transformed images easy distinguish repeatedly detect trained model follows superpoint architecture ease comparison demonstrates similar performance natural ages hpatches dataset performance retina images fundus image registration dataset contain low number corner like features hpatches datasets coverage com puted estimation model quality introduction local image features keypoint detection descrip tor extraction form base computer vision applications notably simultaneous localization mapping slam augmented reality tra ditionally handcrafted local features harris corner detector harris surf funayama chine learning methods shown usefulness task early example fast rosten drummond introduced uses decision trees corner detection improvement hardware deep learning theory pos sible learn descriptor extraction matching example superglue sarlin typically supervised learning limits applicability methods novel domains deﬁnitions machine learning abil ity program improve performance data mitchell deployed feature extrac tion image matching methods applied unlabelled data improvement perfor mance naturally supposes unsupervised learning supervised learning frequently demon strating performance unsupervised training convolutional neural networks feature generation detone truong state art results achieved whole keypoint detection description extraction pipeline paper consideration pattern recognition ters supervised method superpoint detone features simple loss function descrip tors minimises diﬀerence descriptors regions correspond geometrically maximizes diﬀerence heatmap keypoints kind descriptor hints possibility building keypoint detectors unsupervised manner simple loss function popular type keypoints handcrafted pervised detectors corners aforementioned methods fast harris superpoint detect corners line ends surf uses blob detection practical point view ideal keypoint tector optimizes performance down stream task image matching target applica tion slam measure diﬃcult compute optimize assume keypoints possess following properties distributed evenly image repeatability diﬀerent view points tors recognizable distinguishable descrip lie densely paper new unsupervised algorithm simultaneous training keypoint detector descriptor generator proposed single headed neural network built superpoint archi tecture tasks proposed model trained directly target domain need performing costly domain adaptation applicable situations domain adaptation wouldn work large diﬀerence target source domains proposed model achieves competitive performance super point trained dataset pervised training demonstrates perfor mance images low number corner like fea tures resulting model referred hereinafter goodpoint work superpoint detone introduced fast con volutional neural network keypoint detection descriptor extraction training split stages supervised training detector synthetic dataset training detector self labelled natural ages unsupervised training scriptor work follows superpoint architecture sim pliﬁes training procedure removing supervised training self labelling pipeline heads network trained natural ages beginning authors glampoint truong train keypoint detector pairs images homographic transformation method uses non maximum suppression heatmaps images extract candidate keypoints uses matching surf descriptors funayama mine positive negative examples research direction object keypoint detection authors jakab propose supervised keypoint detector learning conditional image generation given pair images objects diﬀerent viewpoint object pose training procedure minimises weighted diﬀerence features extracted image reconstruction reconstruction produced neural network given image keypoints loss function ﬁned here denotes output layer pretrained neural network here keypoint detector neural network learns output heatmaps height width images heatmap corresponds location keypoint normalized softmax function probability distribution authors kulkarni reuse formula tion work jakab restricting static backgrounds diﬀerence jakab introduction feature transport features extracted image generate here keypoint detector outputs heatmaps heatmap image containing isotropic gaussians keypoints spec iﬁed feature extraction network takes background features fea tures locations keypoints images plus features near target keypoints loss squared reconstruction ror ref inen reﬁnenet convolutional generative model net ono advances results perpoint new state art datasets requires ground truth depth camera pose net projects score map source image target image applies non maximum pression sample keypoints generates new target score map gaussian kernel average diﬀerence score maps minimised projection function gaussian kernel application descriptors extracted keypoint locations diﬀerence correspondent non occluded descriptors minimised additional loss keypoint scales orientations architecture overview proposed goodpoint architecture based perpoint architecture consists common vgg backbone followed heads descriptor tector vgg backbone descriptor heads left unchanged activation function training procedure detector head loss function diﬀerent activation function layers leaky relu maas total num ber trainable parameters detec tor implemented similar superpoint dustbin channel detector head outputs tensor doesn aﬀect performance simpliﬁes implementa tion channels now treated equally softmax applied last axis ensure points lie densely softmax makes possible learn only positive examples softmax normalized tensors reshaped form conﬁdence map descriptor head outputs semi dense tensor interpolated keypoint locations training training based homographic warping images noise augmentation loss computed pair images original warped random homography image single homography images mini batch images may warped case still single homography equations don change ﬁnal loss weighted sum losses descriptor loss detector loss weights heatmaps ages descriptors images homographic warp random noise ﬁlters plied independently images details noise augmentation section training keypoint detection inspired expectation maximisation technique network learns output keypoints easy produce trained target keypoints computed following procedure see ﬁgure points found image projected form kproj projected points kproj matched coordinates descriptors nearest neighbour matcher form sets matches kproj figure unsupervised training overview first keypoints descriptors extracted original warped images headed neural network descriptors interpolated location keypoints semi dense output keypoints matched descriptors correctly matched points positive examples detector training interpolated descriptors calculate descriptor loss pairs points match coordinates descriptors pairs present sets matches nearest neighbours compute targets targets projected back image detailed description next section keypoints loss loss function keypoint detector sum neg ative log likelihoods estimated target keypoint posi tions images plus heatmaps diﬀerence lkeypoints lheatmaps lkeypoints logp logph lheatmaps blr blr phi nmask height width mask denotes selection points heatmap weight heatmap diﬀerence blr notes homographic projection heatmap way image note bilinear interpola tion loss high heatmaps similar due blr smoother sum iterates points covered mask image mask image tensor shape image points mask mask projection phinv figure keypoint target estimation kproj geometric match descriptor match projection projection nmask number nonzero elements mask given heatmaps tensors estimated keypoints positions computed following steps keypoint arrays extracted maxpooling diﬀerent sizes descriptor loss maxpool maxpool selecting keypoint region size follows assumption keypoints distributed evenly image densely function maxpool performs maxpooling turns coordinates keypoints array shapes projection points image plane kproj keypoints projected boundaries image discarded dproj descriptors points kproj dproj descriptors extracted image keypoints stay bounds projected image next step match points scriptors coordinates distgeom idxgeom matchgeom kproj idxdesc matchdesc dproj here function matchgeom performs nearest neighbour matching points kproj euclidean distance coordinates mea sure matchgeom returns vectors length equal length kproj ﬁrst distance point kproj nearest point second gives index nearest point idxdesc gives index nearest point distance computed space descriptors idxgeom idxdesc length positive examples keypoints image com puted mean coordinates correctly matching points loss descriptors consists components ldesc lgt lwrong lrandom element vector dproj idxgeom scalar product descriptors keypoints matched coordinates descriptors descriptors normalized scalar product equals cosine sim ilarity lgt maximises similarity descriptors pair points lgt ngt lwrong minimises similarity incorrectly matched pairs descriptors points reasonably dis tant lwrong nwrong idxgeom idxdesc distgeom lrandom minimises diﬀerence randomly sampled scriptors lrandom nrandomnpoints nrandom npoints dproj randomized shuﬄe rows descriptor trix pair dproj belong nearest neighbours deﬁned idxgeom implementation details model implemented pytorch frame work optimization algorithm training adamw loshchilov hutter initial learning rate parameters set default values weight decay default proposed model trained training set images coco dataset lin minimatch composed random crops size weight heatmap diﬀerenceh set network trained constant learning rate ﬁrst epochs epoch ponential decay learning rate epochs noise ﬁlters applied predeﬁned order sequen tially image ﬁlter skipped prob ability filters training coordsmean kproj idxgeom noise augmentation idxgeom idxdesc distgeom θdist indices match geometric distance threshold here coordsmean θdist threshold pixels case distant points matched correctly projected image inverse homography hinv additive gaussian random brightness additive shade hhinv salt pepper targets needed compute equation images motion blur random contrast scale figure random homography homography esti mated random perturbations rectangle points table test results airsim dataset dataset superpoint goodpoint superpoint rotation goodpoint rotation fantasy village precision repeatability coverage harmonic mean precision repeatability coverage harmonic mean precision repeatability coverage harmonic mean precision repeatability coverage harmonic mean village precision repeatability coverage harmonic mean precision repeatability coverage harmonic mean mean recall repeatability coverage harmonic mean mean recall repeatability coverage harmonic mean ﬁlter application image checked validity image considered ruined variance original case ﬁlter skipped homographic augmentation random homography matrices generated prod uct simple transformations random shift points range perspective shift side top bottom points range random homogra phy augmentation applied random rotation sampled range rad figure comparison keypoints left super point points right goodpoint points image points seen goodpoint points doesn correspond corners due unsuper vised learning points coincide cor ners figure comparison keypoints left superpoint points right goodpoint points left superpoint points right goodpoint points thresh olds previous image parameters training here descriptors keypoints experiments compute harmonic mean evaluation metrics gives single number comparison datasets calculate coverage addition ally replication ratio accuracy method ology proposed irschara irschara coverage ratio covered pixels pixels image pixel considered covered lies distances correctly matched keypoint assessing performance experiments headed neural network trade performance detector descriptor networks computing single metric combines points repeatability precision matching descriptors way break ties multiple model variants authors paper propose following like metric precision repeatability precision repeatability harmonic mean precision matching key points repeatability tuning hyper figures show side side comparison networks tend select keypoints threshold set ﬁrst image networks detect seen unsu number keypoints pervised model biased corner features may advantage disadvantage depending scene properties example images project website https github com singnet image matching table goodpoint superpoint hpatches dataset table tests fire dataset model θdist θkeypoint light replication view replication light accuracy view accuracy light coverage view coverage harmonic mean airsim village dataset airsim village dataset introduced yashenko contains sequences images made varying lighting camera positions contains ground truth camera pose depth formation may evalua tion slam methods feature extrac tion matching sequences made recording camera motion synthetic environment test resolution matching shift frames radius coverage set precision repeatability calculated average matching ways model evaluated roll original dataset wasn generated roll camera motion results presented table threshold correct match θkeypoint goodpoint superpoint θdesc models goodpoint demonstrates precision lower superpoint repeatability keypoints hpatches hpatches dataset methodology net superpoint papers thresholds correct match set pixels coverage radius results presented table test demonstrates models similar performance superpoint accurate estimating keypoints positions goodpoint tends select points giving higher coverage lower replication ratio fundus image registration dataset fire hernandez matas dataset contains pairs retinal images ground truth corre spondences number points allows homography estimation dataset contains masks global local registration methods dataset coverage radius set point tuned images fire only change training pipeline diﬀerent size crop window original trained coco ﬁne tuned versions evaluated results presented table goodpoint demonstrates coverage accuracy coverage replication harmonic mean goodpoint superpoint tuned fire table goodpoint performance fire thresh old accuracy coverage replication harmonic mean supervised superpoint shows unsupervised learning keypoint detector introduced bias model trade accuracy coverage shown table higher threshold keypoint detector possible achieve accu racy glampoint fire dataset cov erage replication ratio reported article truong conclusion future work novel method joint training keypoints detection description introduced method fully unsupervised applied train model directly set unlabelled images method train convolutional model named goodpoint goodpoint based superpoint architecture ease comparison only minor changes intro duced removal dustbin channel keypoint detector proposed train ing method result goodpoint number layers parameters superpoint trained model evaluated diverse datasets demonstrated performance natural thetic images rich hpatches airsim village poor fire corner features goodpoint tends produce dense detections corresponds higher coverage results open way following improvements research directions replacement maxpooling keypoint extrac tion theoretically sound sampling methods greedy sampling augmenting local descriptors global features way superglue match ing sarlin references detone malisiewicz rabinovich superpoint self supervised interest point detection description proceedings ieee con figure points matches hpatches dataset corner edge detector alvey vision confer ence citeseer hernandez matas zabulis triantafyllou anyfanti douma argyros fire fundus image registration dataset journal mod eling ophthalmology irschara zach frahm bischof structure motion point clouds fast ieee conference cation recognition computer vision pattern recognition ieee jakab gupta bilen vedaldi unsupervised learning object landmarks conditional image generation advances neural processing systems kulkarni gupta ionescu borgeaud reynolds zisserman mnih unsu pervised learning object keypoints perception control advances neural cessing systems lin maire belongie hays perona ramanan doll zitnick crosoft coco common objects context euro pean conference computer vision springer loshchilov hutter decoupled weight cay regularization arxiv preprint arxiv figure goodpoint results fire top ﬁne tuning fire dataset bottom ference computer vision pattern recognition workshops funayama yanagihara van gool tuyte laars bay robust interest point tector descriptor patent harris stephens combined maas hannun rectiﬁer nonlinearities improve neural network acoustic mod els proc icml mitchell machine learning ono trulls fua net learning local features images advances neural processing systems rosten drummond machine learning high speed corner detection european con ference computer vision springer sarlin detone malisiewicz rabinovich superglue learning feature match arxiv preprint ing graph neural networks arxiv truong apostolopoulos mosinska stucky ciller zanet glampoints greed ily learned accurate match points proceedings ieee international conference computer sion yashenko belikov peterson potapov distillation neural network models detection description key points images,"['points', 'image', 'keypoints', 'keypoint', 'images']"
Review on 3D Lidar Localization for Autonomous Driving Cars,review lidar localization autonomous driving cars mahdi elhousni xinming huang abstract lidar sensors bound core sensors achieving full autonomy self driving cars lidars able produce rich dense precise spatial data tremendously help localizing tracking moving vehicle paper review latest ﬁnding lidar localization autonomous driving cars analyze results obtained method effort guide research community path promising introduction lately autonomous driving researched topics scientiﬁc community race full autonomous driving cars level autonomy categorized sae international mainly fueled hope eliminating human errors comes driving huge impact daily lives according report department transportation usa self driving cars reduce trafﬁc fatalities order car drive autonomously ﬁrst challenge traditional pipeline try solve localize car localization context means ﬁnding position orientation vehicle inside map deﬁning map means important paper focus autonomous driving cars adc perception system consistent only light detection ranging lidar sensor sensor uses laser light order measure distances capable producing pointclouds representation space point contains coordinates surface reﬂected laser beam originating lidar sensor maps localize adc match avail able sensor data given rise pointcoud based maps maps constructed concatenating successive lidar scans ofﬂine navigation process optimizing taking advantage odometry generated using lidar data combining loop closure mechanism later known simultaneous localization mapping slam approaches advantages disadvantages discussed details decided focus localization using lidar following reasons lidar data compared perception sensors richest detailed term spacial results lidar sensor practically accurate comes solving spatial based challenges localizing vehicle observed price sensor going down constantly years ago today making sensor accessible public affordable car manufacturers localization lidars face multiple issues revolve efﬁciency real time execution lidar data tends heavy size containing individual points scan frequency processing data quick fashion guarantee real time necessities adcs challenging demands efﬁcient processing pipeline sort downsampling feature extraction method generating odometry measurement localizing vehicle essential step multiple approches proposed year utilize data lidars calculate displacement subject robot decided separate distinct categories registration based methods combined map built ofﬂine methods take advantage advances achieved pointclouds registra tion accurate types approaches tend slow achieve real time processing relying lidar data only methods seen dense methods take advantage points present lidar data features based methods inspired popular meth ods relying feature extraction matching approaches design relevant features space calculate displacements successive scans accuracy real time processing methods satisfactory poor results expected dealing rough maneuvers high speed movements methods seen sparse method only select number points lidar data deep learning based methods deep learning solving localization challenges gaining popularity lately camera images ﬁrst try predict odometry pair images results acceptable still outperforming state art lately works exploring lidar data results promising results reported publications categories compared kitti odometry dataset popular benchmark ﬁeld goal survey review present relevant work lidar localization compare results reported literature discuss strengths weaknesses lidar localization autonomous driving cars review discuss methods literature localization moving vehicle achieved using lidar sensor only separated methods categories registration features deep learning listed table table lidar localization methods features lsf posemap cpfg slam planes slam loam registration icp ndt salo imls slam suma suma proba surfel cls slam dlo deep learning lbo deeppco deeplo locnet lorax segmap net bias cor net deepicp cae registration based methods section review localization methods based point clouds registration approaches reg istration transforms pair point clouds order align coordinates frame making possible deduct transformation scans context adc localization registration ways combining incoming scans portions built point cloud map order localize vehicle combining successive lidar scans order calculate odometry vehicle point cloud registration areas shape alignment scene reconstruction iterative closest point icp algorithm popular icp algorithm transformation source target point cloud iteratively optimized minimizing error metric points point clouds multiple variants algorithm developed point line icp point plane icp generalized icp icp algorithm standard years solve point cloud registration tasks methods incorporate localization pipeline designed combined loop closure mechanism pose graph building process order reduce accumulated errors consecutive registrations recently odometry pipeline proposed integrates knowledge lidar sensor physics improved icp algorithm novel downsampling point matching rejection methods downsampling lidar scans using normal covariance filter ncf keeps only points precises normals hand outlier rejection matching points achieved geometric correspondance rejector taking advantage rings structure lidar scans normals previously calculated author deﬁnes threshold named highest neighbor beam distance matching rejection criteria plugging method icp algorithm author reports drop drift odometry kitti dataset icp algorithm eventually surpassed normal distribution transform ndt algorithm first developed assist autonomous mining vehicles ndt point cloud registration algorithm extend ndt algorithm space similarly icp algorithm transformation source target point cloud iteratively optimized case error minimized pairs points point clouds ﬁrst transformed probability density function pdf based mean covariance points present computed voxels pdf newton algorithm ﬁnd spatial transformation extension ndt algorithm proposed named probabilistic ndt attempts deal sparsity classical ndt representation resulting hard threshold number points voxel considered computing mean covariance needed ndt based number points probability generates denser distribution results bump accuracy translation rotation methods icp algorithm ndt gorithm produce accurate transformations lidar pairs context adc methods rarely meet real time execution criteria methods accurate initial guess needed start optimization process avoid local minimas means additional sensor imu produce odometry initial guess lidar only setup classical slam approach authors propose steps algorithm named imls slam first dynamic object removal simpliﬁed clustering scans removal small clusters second step apply sampling strategy based observability point order down sample scan ﬁnally matching step transformation optimized following scan model matching strategy using implicit moving least square imls representation popular processing approach applied scans attempting register compute surfel surface element representation point clouds surfel map built incoming scan converted vertex normal maps calculate odometry vehicle called frame model icp algorithm surfel map ﬁnd loop closure candidates order optimize trajectory vehicle minimize drift extension method proposed semantic segmentation spherical projection dar data remove dynamic objects improve frame frame matching enforcing semantic constraints frame model icp algorithm surfel representations computed ellipsoid surfel map esm disk surfel map dsm esm due sparsity only localization dsm denser esm reconstruct surrounding environment spirit collar line segments cls construc tion useful processing method makes possible achieve level accuracy aligning point clouds lidar scans transformed line clouds sampling line segments neighbouring points neighbouring rings line clouds aligned using iterative approach first center points generated lines calculated points ﬁnd transformation successive scans ﬁnding lines target pointcloud center closest lines source pointcloud additional post processing tricks boost accuracy using previous transformations predict initialize next pose estimation step reducing dimensionality lidar data yield reasonable results incoming scans projected grid map occupancy height grid map equivalent gray scale image register scans based photo metric errors camera data features based methods section tackle localization methods based features extraction matching fea tures interest points represent recognizable areas consistent time space corners planes commonly object detection tasks features represented using unique vector called feature descriptor match features point clouds ﬁnding sufﬁcient consistent matches calculate transform scans using optimization method construct odometry measurement authors propose study focuses ﬁnding type data features observed trying achieve accurate localization adc authors here argue features built extracted based distribution clusters points experiments show distribution points changes drastically scene making method instable approach named posemap proposed authors argue coherent map representation environment achieve high quality localization method takes advantages build pointcloud map using subsampled based overlap threshold order produce simple sparse light representation environment key poses maintained map representation seen collection submaps updated independently points time localization solved using sliding window approach simply using closest submaps current vehicle position minimizing distance old features new ones geared road environment method proposed named cpfg slam inspired icp ndt algorithms relies features probability grid map taking advantage nearest neighbor grid nearest neighbor point authors able matches registers point cloud grid map efﬁciently expectation maximization algorithm estimate pose ﬁnal optimization problem solved using levenberg marquardt algorithm localization methods try take advantage predom inant geometries present environment adc moving plane extraction algorithms combined frame frame techniques order produce pose estimation vehicle compared results obtained icp algorithm plane extraction alignment methods show great improve ment accuracy speed pure engineering solution requires tweak adapt multiple parameters features based localization methods known generate impressive results accuracy speed currently holding ﬁrst spot kitti odometry leaderboard method proposed starts extracting planar corner features based smoothness occlusion points features matched patches points following scan levenberg marquardt method solve lidar motion slam pipelines map built background slower frequency odometry estimation helps improving ﬁnal localization results extension method proposed order improve speed guarantee real time aspect odometry calculation improvements reside taking advantage presence ground moving unreliable features using step levenberg marquardt method speed optimization step still remaining issues loam pipeline odometry drift due accumulated errors plugging loop closure mechanism pipeline solve issue shown deep learning based methods section review localization methods based deep learning still young approach odometry localization estimation deep learning gaining popularity lately proved promising camera domain methods pointnet poinetnet showed efﬁcient deep neural networsk attempting solve pointclouds challenges usu ally formulated regression problem methods involving deep learning try solve task end end fashion using raw pointclouds inputs directly predicting displacements vehicle using single network trying substitute parts established classical pipelines beneﬁt generalizations possible deep learning networks ﬁrst method proposed solve task using deep learning approach idea here try take challenge back image domain attempting solve directly pointcloud order simplify data input network incoming lidar frames ﬁrst projected space produce panoramic depth images fed simple branch convolution network attempt regress values displacement change orientation vehicle input frames results obtained authors subpar compared state art able prove exploring deep learning solve task eventually lead results panoramic depth images popular representation lidar data method makes deeppco projected lidar frames fed branch network ﬁrst branch predict translation vehicle second predicts rotation method attempts simplify input data projecting space presented here lidar frames projected using spherical coordinate system generate new representations vertex map representing location point normal map representing values normals point proposed network mainly composed residual blocks major branches first named vertexnet takes input vertex maps predict translation subsequent frames second branch named normalnet takes input normal maps designed predict rotation subsequent frames output branches combined order construct full transformation lidar frames order train full network end end fashion authors propose training schemes loss function based availability labeled data first classical supervised loss labeled data compared network prediction order optimize weights network second unsupervised loss labeled data needed icp algorithm guide network correct motion predictions recently solution coined cae proposed unsupervised convolution auto encoder extract features spherical projections lidar data multi scale fashion aditional auto encoder generate feature descriptors match points using ransac based frame frame matching finally icp algorithm reﬁne odometry results effort simply input data handcrafted rotational invariant representation rir based rings distribution point clouds presented authors claim thanks representation global localization problem reformulated identity veriﬁcation solved using siamese network named locnet takes input subsequent rir aims optimize contrastive loss function output locnet dimension reduced feature vector later complete slam pipeline mcl icp algorithm generate ﬁnal transformation coarse ﬁne manner lorax algorithm proposed proach introduces notion super points subset points located inside sphere local surface projected space form depth maps depth maps ﬁltered using series test leave only relevant super points encoded using pca deep auto encoder candidates matching selected based euclidien distance features engaging coarse registration step iterative approach involving ransac algorithm ﬁnal step order ﬁne tune results registration step icp algorithm improve accuracy whole pipeline series papers eventually led ﬁnal segmap method authors explore efﬁciently extract encode segments point clouds using simple convolution networks hope solving localization mapping tasks contribution approach data driven segment descriptor extracted using network composed series convolutional fully connected layers descriptor extractor network trained using loss function composed parts classiﬁcation loss reconstruc tion finally extracted segments candidate correspondences found using knearest neighbors algorithm makes possible solve localization task note segmap descriptor versatile descriptor solve tasks object classiﬁcation method discussed previously inevitably suffer presence dynamic objects cars pedes trians scene trying regress tion frames removing dynamic object scene known improve odometry results slam pipelines detecting deleting dynamic objects scene supervised manner introduces extra level complexity lead higher processing times unstable results order solve issues unsupervised manner authors proposed train encoder decoder branch task dynamic mask prediction optimizing geometric consistency loss function areas geometric consistency modeled thanks normals point cloud data full network named net trained end end fashion combin ing geometric consistency loss odometry regression loss cross entropy loss regularization purposes table comparison localization methods training kitti dataset method icp salo cls slam suma suma imls slam loam net deeplo deeppco deepicp bias cor sequences avg table iii comparison localization methods test kitti dataset method imls slam cpfg slam suma suma loam cae translation error rotation error deg runtime learning localize vehicle using lidar frames directly methods attempt learn error model classical pipeline words deep learning correct odometry measurements resulting powerful ﬂexible plug module authors proposed learn bias correction term aimed improve results classical state estimator takes lidar data input gaussian process model model odometry errors independently carefully selected input features concentrated dof affected errors advanced method named net posed linked bias correction theme predicting full transformation frames authors here proposing network attempts learn residual value traditional localization system ground truth relevant features ﬁrst extracted fed minipointnet generate corresponding feature descriptors cost volume constructed solution space regularized convolutional neural networks additionally rnn branch added network structured guarantee temporal smoothness displacements predictions complete general variant net proposed authors named deepicp here features extracted using point net ﬁlterd using weighting layer only keeps relevant ones similarly previous method features descriptors computed using minipointnet structure fed corresponding point generation layer generate corresponding key points target point cloud order regress ﬁnal value transformation loss function combined hoping encode local similarities global geometric constraints iii evaluation discussion compare previously cited methods based reported results kitti odometry benchmark popular large scale dataset outdoor odometry evaluation contains sequences recorded using velodyne hdl mounted top car lidar scans processed compensate motion vehicle ground truth ﬁrst sequences obtained using advanced gps ins system table lists reported results training dataset table iii lists results test dataset reported kitti ofﬁcial leaderbord note only consider results involve loop closure mechanims loam still occupies ﬁrst position kitti leaderboard clear methods involving deep learning accurate exemple deepicp reported average result outperform proposed method training dataset hard qualify state art methods reason deepicp reporting takes seconds register pair frames slow deloyed real autonomous driving car operating real life situations results approaches test dataset reported results test dataset prove method capable real scenarios only data deep neural networks seen loam variant remain best option trustworthy real autonomous driving deployment conclusion paper reviewed analyzed compared dis cussed recent advances ﬁndings area lidar localization autonomous driving cars considered systems only sensor lidar due increasing importance sensor accurate perception localization systems nowdays addition increase availability general public manufacturers results kitti odom etry dataset reported cited papers compiled compared leading following statement deep learning based methods shown producing promising results represent right path follow order solve challenge future methods based feature detection matching still considered state art due proven stability deployed real life scenarios references tam cheng lai langbein liu mar martin sun rosin registration point clouds meshes survey rigid nonrigid ieee transactions visualization computer graphics vol mur artal montiel tardos orb slam versatile accurate monocular slam system ieee transactions robotics vol mur artal tard orb slam open source slam system monocular stereo rgb cameras ieee transactions robotics vol scaramuzza fraundorfer visual odometry tutorial ieee robotics automation magazine vol konda memisevic learning visual odometry convolutional network visapp wang clark wen trigoni deepvo end end visual odometry deep recurrent convolutional neural networks ieee international conference robotics automation icra ieee clark wang wen markham trigoni vinet visual inertial odometry sequence sequence learning problem thirty first aaai conference artiﬁcial intelligence yang wang stuckler cremers deep virtual stereo odometry leveraging deep depth prediction monocular direct sparse odometry proceedings european conference computer vision eccv geiger lenz stiller urtasun vision meets robotics kitti dataset international journal robotics research vol segal haehnel thrun generalized icp robotics science systems vol seattle mendes koch lacroix icp based pose graph slam ieee international symposium safety security rescue robotics ssrr yoneda niknejad ogawa hukuyama mita lidar scan feature localization highly precise map ieee intelligent vehicles symposium proceedings nicolai skeele eriksen hollinger deep learning laser based odometry estimation magnusson lilienthal duckett scan registration autonomous mining vehicles using ndt journal field robotics vol zhou tang qian fang lidar odometry outdoor mobile robots using ndt based scan matching gps denied environments ieee annual international conference cyber technology automation control intelligent systems cyber ieee egger borges catt pfrunder siegwart dub posemap lifelong multi environment lidar localization ieee rsj international conference intelligent robots systems iros ieee wang saputra zhao gusmao yang chen markham trigoni deeppco end end point cloud odometry deep parallel neural network arxiv preprint arxiv cho kim kim deeplo geometry aware deep lidar odometry arxiv preprint arxiv chen gong xiong cpfg slam robust simultaneous localization mapping based lidar road environment ieee intelligent vehicles symposium june deschaud imls slam scan model matching based data corr vol abs online http arxiv org abs pathak birk vaskevicius pﬁngsthorn schwertfeger poppinga online dimensional slam registration large planar surface segments closed form pose graph relaxation journal field robotics vol grant voorhies itti finding planes lidar point clouds real time registration ieee rsj international conference intelligent robots systems ieee yin tang ding wang xiong locnet global localization point clouds mobile vehicles ieee intelligent vehicles symposium ieee behley stachniss efﬁcient surfel based slam using laser range data urban environments zhang singh loam lidar odometry mapping real time shan englot lego loam lightweight ground optimized lidar odometry mapping variable terrain ieee rsj international conference intelligent robots systems iros ieee zuo zhang liu lloam lidar odometry mapping loop closure detection based correction ieee international conference mechatronics automation icma aug lin zhang fast complete point cloud based loop closure lidar odometry mapping elbaz avraham fischer point cloud registration localization using deep neural network auto encoder ieee conference computer vision pattern recognition cvpr july chen palazzolo gigu behley stachniss suma efﬁcient lidar based semantic slam cramariuc dub sommer siegwart gilitschen ski learning segment descriptors place recognition arxiv preprint arxiv dube dugas stumm nieto siegwart cadena segmatch segment based place recognition point clouds dub gollub sommer gilitschenski siegwart cadena nieto incremental segment based localization point clouds ieee robotics automation letters vol dub gawel sommer nieto siegwart cadena online multi robot slam system lidars ieee rsj international conference intelligent robots systems iros sep dub cramariuc dugas nieto siegwart dena segmap segment mapping using data driven descriptors arxiv preprint arxiv park kim moghadam fookes sridharan proba bilistic surfel fusion dense lidar mapping ieee international conference computer vision workshops iccvw chen wang wen cheng net deep real time lidar odometry proceedings ieee conference computer vision pattern recognition velas spanel herout collar line segments fast odometry estimation velodyne point clouds ieee international conference robotics automation icra tang yoon pomerleau barfoot learning bias correction lidar only motion estimation conference computer robot vision crv ieee sun zhao dlo direct lidar odometry outdoor environment ieee intelligent vehicles symposium ieee zhou wan hou song net learn ing based lidar localization autonomous driving proceedings ieee conference computer vision pattern recognition wan zhou yuan song deepicp end end deep neural network point cloud registration arxiv preprint arxiv deepvcp end end deep neural network point cloud registration proceedings ieee international conference computer vision yin zhang liu liang wang maanp hyypp chen cae lidar odometry leveraging fully unsupervised convolutional auto encoder interest point detection feature description arxiv preprint arxiv chen medioni object modelling registration multiple range images image vision computing vol zhang iterative point matching registration free form curves surfaces rusinkiewicz levoy efﬁcient variants icp algo rithm dim vol censi icp variant using point line metric low linear least squares optimization point plane icp surface registration chapel hill university north carolina vol kovalenko korobkin minin sensor aware lidar odometry european conference mobile robots ecmr ieee magnusson dimensional normal distributions trans form efﬁcient representation registration surface analysis loop detection dissertation orebro universitet hong lee probabilistic normal distributions transform representation accurate point cloud registration kuramachi ohsato sasaki mizoguchi icp slam odometry free mapping system robust dof pose estimation ieee international conference robotics biomimetics robio engel koltun cremers direct sparse odometry ieee transactions pattern analysis machine intelligence mar rusu blodow beetz fast point feature histograms fpfh registration ieee international conference robotics automation ieee rusu bradski thibaux hsu fast recognition pose using viewpoint feature histogram proceedings ieee rsj international conference intelligent robots systems iros taipei taiwan october steder rusu konolige burgard narf range image features object recognition guo sohel bennamoun wan rotational projection statistics local surface description object recog nition international journal computer vision vol bosse zlot continuous scan matching spinning laser ieee international conference robotics automation ieee guibas pointnet deep learning point sets classiﬁcation segmentation proceedings ieee conference computer vision pattern recognition hadsell chopra lecun dimensionality reduction learning invariant mapping ieee computer society conference computer vision pattern recognition cvpr vol ieee fox burgard dellaert thrun monte carlo localiza tion efﬁcient position estimation mobile robots,"['lidar', 'point', 'odometry', 'ieee', 'localization']"
